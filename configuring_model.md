# Configuring The Model
---
To test out the model once all of the dependencies have been installed, from one terminal run this command in the repository root folder:
`ollama serve`

If this command runs successfully, then in another terminal from the repository root folder run:
`streamlit run main.py`
If this runs successfully, you should see something like:
```
  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:<your-port>
  Network URL: http://<your-ip-address>
```